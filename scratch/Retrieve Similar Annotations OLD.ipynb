{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel #same as cosine similarity\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global variables\n",
    "annotation_to_song = {} # annotation_id as key and song_id as value\n",
    "song_to_name = {} #song_id to name of song\n",
    "annotation_to_text = {} #annotation_id to annotation text\n",
    "annotation_to_fragment = {} #annotation_id to lyric fragment\n",
    "\n",
    "with open('songs.json') as json_file:  \n",
    "    all_songs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionarys(json_file=\"songs.json\", annotation_to_song={}, song_to_name={},\n",
    "                       annotation_to_text={}, annotation_to_fragment={},\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    Using songs.json as json_data\n",
    "    Creates annotation dictionary: {annotation_id:[song_id,fragment/text,annotation_text]}\n",
    "    \"\"\"\n",
    "    \n",
    "    #load song json file\n",
    "    with open(json_file) as song_json: \n",
    "        songs = json.load(song_json)\n",
    "        \n",
    "        #iterate through all songs and input data accordingly\n",
    "        for song_id in songs:\n",
    "            song_data = songs[song_id]\n",
    "            \n",
    "            if song_id not in song_to_name:\n",
    "                song_to_name[song_id] = song_data[\"full_title\"]\n",
    "            \n",
    "            #process annotations\n",
    "            for referent in song_data[\"referents\"]:\n",
    "                lyric_fragment = referent[\"lyric\"]\n",
    "                for annotation in referent[\"annotations\"]:\n",
    "                    annotation_id = annotation[\"id\"]\n",
    "                    annotation_text = annotation[\"annotation\"]\n",
    "                #annotation_votes = referent[\"votes_total\"] # here is where we would record vote numbers\n",
    "                \n",
    "                if annotation_id not in annotation_to_song:\n",
    "                    annotation_to_song[annotation_id] = song_id\n",
    "                    \n",
    "                if annotation_id not in annotation_to_text:\n",
    "                    annotation_to_text[annotation_id] = annotation_text\n",
    "                    \n",
    "                if annotation_id not in annotation_to_fragment:\n",
    "                    annotation_to_fragment[annotation_id] = lyric_fragment\n",
    "                    \n",
    "    print(\"Processed {} annotations\".format(len(annotation_to_text)))\n",
    "    return (annotation_to_song,song_to_name,annotation_to_text,annotation_to_fragment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 4639 annotations\n"
     ]
    }
   ],
   "source": [
    "#Create used variables and dictionaries\n",
    "annotation_to_song,song_to_name,annotation_to_text,annotation_to_fragment = create_dictionarys()\n",
    "vectorizer = TfidfVectorizer(max_features =  5000,\n",
    "                           stop_words = \"english\",\n",
    "                           max_df = 0.8, min_df = 10,\n",
    "                          norm = 'l2')\n",
    "tf_idf = vectorizer.fit_transform(list(annotation_to_text.values())).toarray()\n",
    "index_to_annotation = {i:v for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "index_to_id = {i:v for i, v in enumerate(list(annotation_to_text.keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar(query,n_results):\n",
    "    \"\"\"\n",
    "    finds n most similar annotations to query\n",
    "    \"\"\"\n",
    "    #Define used global variables\n",
    "    global vectorizer, tf_idf, annotation_to_text, annotation_to_song, annotation_to_fragment,song_to_name\n",
    "\n",
    "    #vectorie query\n",
    "    query_vector = vectorizer.transform([query])    \n",
    "    \n",
    "    #find cosine similarities and the indices of related docs\n",
    "    cosine_similarities = linear_kernel(query_vector, tf_idf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[-n_results:]\n",
    "    \n",
    "    \n",
    "    #find highest similarity scores\n",
    "    sim_scores = cosine_similarities[related_docs_indices] \n",
    "    \n",
    "    #find ids of most similar annotations\n",
    "    annotation_ids = [index_to_id[index] for index in related_docs_indices] #can later be used to find lyric fragment maybe\n",
    "    \n",
    "    \n",
    "    #define output and input data\n",
    "    output_array = [] #annotations sorted from most similar to least\n",
    "    for i in range(1,n_results+1):\n",
    "        _id = annotation_ids[-i]\n",
    "        data = {} #data object contains the below fields\n",
    "        data[\"id\"] = _id\n",
    "        data[\"song\"] = song_to_name[annotation_to_song[_id]]\n",
    "        data[\"annotation\"] = annotation_to_text[_id]\n",
    "        data[\"lyric\"] = annotation_to_fragment[_id]\n",
    "        data[\"similarity\"] = sim_scores[-i]\n",
    "        data[\"producer\"]\n",
    "        output_array.append(data)\n",
    "        \n",
    "    print(\"Finished finding similar annotations for query: {}\".format(query))\n",
    "    return output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'producer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d2776db3fb1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Testing output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_most_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"racism\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#finding 5 most similar annotations for the query 'racism'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}).\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\tSong: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"song\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-8a99bb3d9703>\u001b[0m in \u001b[0;36mfind_most_similar\u001b[1;34m(query, n_results)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lyric\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotation_to_fragment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"similarity\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"producer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moutput_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'producer'"
     ]
    }
   ],
   "source": [
    "#Testing output\n",
    "test_output = find_most_similar(\"racism\",5) #finding 5 most similar annotations for the query 'racism'\n",
    "for i,data in enumerate(test_output):\n",
    "    print(\"{}).\".format(i+1))\n",
    "    print(\"\\tSong: {}\".format(data[\"song\"]))\n",
    "    print(\"\\n\\tLyric Fragment: {}\".format(data[\"lyric\"]))\n",
    "    print(\"\\n\\tAnnotation: {}\".format(data[\"annotation\"]))\n",
    "    print(\"\\n\\tSimilarity Score: {}\".format(data[\"similarity\"]))\n",
    "    print(\"_\"*125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing some recommendation stuff\n",
    "def recommend_artists(keywords=None,current_artist=None):\n",
    "    \"\"\"\n",
    "    Recommendation based on keywords and artists\n",
    "    \"\"\"\n",
    "    #useful global variables\n",
    "    global all_songs\n",
    "    \n",
    "    #song_id_scores to keep track of cumulative relevance for songs\n",
    "    song_scores = {}\n",
    "\n",
    "    #create song_id to artist_names dict\n",
    "    song_to_artist = {}\n",
    "    for song_id in all_songs:\n",
    "        if song_id not in song_to_artist:\n",
    "            song_to_artist[song_id] = all_songs[song_id][\"artists_names\"]\n",
    "            song_scores[song_id] = 0\n",
    "    artists_array = []\n",
    "    for artists in song_to_artist.values():\n",
    "        artists_array.append(artists)\n",
    "    \n",
    "    #If no starting data, return most popular artist\n",
    "    if not keywords and not current_artist:\n",
    "        return Counter(artists_array).most_common(5)\n",
    "\n",
    "    \n",
    "    if current_artist:\n",
    "        \n",
    "        \n",
    "    if keywords:\n",
    "        for k_word in keywords: #implying they're not stop words\n",
    "            most_similar_songs = find_most_similar(query,len(all_songs))\n",
    "            for i,song_data in enumerate(most_similar_songs):\n",
    "                song_scores[song_data[\"id\"]]+=i\n",
    "                \n",
    "recommend_artists()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
